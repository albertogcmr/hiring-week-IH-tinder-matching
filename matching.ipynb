{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "from func_matching import calculate_match\n",
    "from func_args import get_args\n",
    "\n",
    "from func_aquisition import adquisition_survey\n",
    "from func_outputs import outputs, create_matrix_matching\n",
    "from func_normalize import *\n",
    "\n",
    "\n",
    "def least_common(queue):\n",
    "    ''' Ordenar por menos número de entrevistas en la cola '''\n",
    "    res = sorted(queue, key=queue.get, reverse=False)\n",
    "    return res\n",
    "\n",
    "def get_next_interview(lista_matching_ordenada, used, students_dict_queue): \n",
    "    \n",
    "    # ordena los estudiantes por prioridad según el que tenga menos entrevistas concertadas\n",
    "    students_ordered = least_common(students_dict_queue) \n",
    "\n",
    "    for student in students_ordered: # según el orden de los menos entrevistados\n",
    "        if student not in used: \n",
    "            for match in lista_matching_ordenada:\n",
    "                if match['company'] not in used and student == match['student']: # TO DO all() \n",
    "                    return match # Devuelve el primer match válido, según el orden de least_common()\n",
    "    return None # Ningún matcha válido\n",
    "    \n",
    "def get_rondas(lista_matching, n_rondas, students, companies): \n",
    "    lista_matching_ordenada = sorted(lista_matching, key = lambda x: x['weight'], reverse=True)\n",
    "    students_dict_queue = generate_student_interviews(students)\n",
    "    \n",
    "    res = []\n",
    "    for ronda in range(n_rondas): # rondas\n",
    "        used = []\n",
    "        for _ in range(len(companies)): # num mesas = num companies\n",
    "            \n",
    "            m = get_next_interview(lista_matching_ordenada, used, students_dict_queue)\n",
    "            if m == None: \n",
    "                break\n",
    "            student, company, w = m['student'], m['company'], m['weight']\n",
    "            used.extend([student, company]) # añadimos empresa y compañia para que no vuelvan a aparecer en esta ronda\n",
    "            lista_matching_ordenada.remove(m) # eliminamos el matching para que no se repita\n",
    "\n",
    "            res.append({'ronda': ronda, 'company': company, 'student': student, 'weight': w})\n",
    "            students_dict_queue[student] += 1\n",
    "    return res    \n",
    "\n",
    "def generate_student_interviews(students_list): \n",
    "    '''\n",
    "    input: list of students\n",
    "    output: dictionary key (student), value (0)\n",
    "    '''\n",
    "    return {student: 0 for student in students_list}\n",
    "\n",
    "def shuffle_rondas(lista_interviews): \n",
    "    rondas = sorted(list({interview.get('ronda') for interview in lista_interviews}))\n",
    "    nuevas_rondas = [r for r in rondas]\n",
    "    shuffle(nuevas_rondas)\n",
    "    \n",
    "    modificacion_rondas = {antigua: nueva for antigua, nueva in zip(rondas, nuevas_rondas)}\n",
    "\n",
    "    for interview in lista_interviews: \n",
    "        interview['ronda'] = modificacion_rondas.get(interview['ronda'])\n",
    "        \n",
    "    lista_interviews = sorted(lista_interviews, key=lambda x: x['ronda'])\n",
    "    return lista_interviews\n",
    "\n",
    "def main(): \n",
    "    # Captura de argumentos. \n",
    "    bootcamp, companies_filename, students_filename, n_rondas = get_args()\n",
    "    \n",
    "    # DFs limpios\n",
    "    df_companies, df_students = adquisition_survey(bootcamp, companies_filename, students_filename)\n",
    "    \n",
    "    # Normalize\n",
    "    students, companies = normalize_2dfs(df_students, df_companies)\n",
    "\n",
    "    # TO DO: crear la tabla matching\n",
    "    lista_matching = calculate_match(students, companies, bootcamp)\n",
    "\n",
    "    lista_interviews = get_rondas(lista_matching, n_rondas, students.index, companies.index)\n",
    "    \n",
    "    lista_interviews = shuffle_rondas(lista_interviews)\n",
    "    \n",
    "    outputs(lista_interviews, lista_matching)\n",
    "\n",
    "\n",
    "if __name__== '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
